# Team wiki - Team 2

# W4M2

택시의 수요가 일정하지 않고, 특정 시간대에 특정 장소에서 수요가 갑자기 증가하는 경우가 있다. 이 경우에도 수요를 최대한 해소할 수 있도록 자율주행 택시를 배차하는 전략을 짜는 product를 제공한다.

Pick Up Location, 요일, 시간대 세 가지 기준으로 그룹을 만들어서 각각의 호출 횟수를 count한 후 정렬해보았다. Location이 ID로만 떠서 lookup table csv 파일을 JOIN하여 다시 나타냈다.
<img width="1354" height="411" alt="image" src="https://github.com/user-attachments/assets/3412d0fa-b41e-42f8-8bb8-4e2a12bd5d5d" />

Top 10을 뽑아본 결과, 맨해튼이 압도적으로 많았다. 이는 맨해튼 내에 술집(bar, pub, lounge)들이 많기 때문이다. [Top 10 bars & lounges](https://www.yelp.com/search?find_desc=Bars+and+Lounges&find_loc=Manhattan%2C+NY&sortby=review_count) 호출한 시간대도 금요일에서 토요일로 넘어가는 밤 11시 ~ 새벽 1시와 토요일에서 일요일로 넘어가는 밤 11시 ~ 새벽 1시가 많았다. 주말에 회식, 술 약속 등을 즐긴 뒤에 안전한 귀가를 위해 택시를 탑승하는 사람에 대한 케이스가 많다고 추측했다.

추가로 10등에 위치해있는 JFK 공항이 많은 이유는 다음 이유로 추측된다. 뉴욕의 높은 집값에 못이겨 주말동안 다른 지역에서 지내거나, 주말동안 다른 지역으로 여행을 다녀왔다가 일요일 밤 10시에 JFK에 도착한 사람들이 숙소로 가기 위해 택시를 많이 부른 것으로 예상했다.

이러한 분석 결과를 바탕으로, 자율 주행 택시를 뉴욕 시내에 배치할 때, 금요일에서 토요일로 넘어가는 밤 11시 ~ 새벽 1시와 토요일에서 일요일로 넘어가는 밤 11시 ~ 새벽 1시에 맨해튼 내에 더 많이 있을 수 있도록 배치하고, JFK 공항 근처에도 일요일 오후 10시에 많이 배치하는 전략을 세울 수 있다.

---

# W4M3

## 가장 인상 깊었던 내용

10년 사이 웹 크롤링의 주요 병목 현상이 완전히 바뀌었음

과거에는 네트워크 대역폭이나 DNS 조회가 가장 큰 문제였지만, 이제는 하드웨어와 인프라의 발전으로 이 부분이 거의 문제가 되지 않음. 

- CPU 병목: 대부분의 웹사이트가 SSL/TLS 암호화를 사용하면서, 암호화 통신을 위한 핸드셰이크 과정이 CPU에 큰 부담을 줌. 네트워크가 아니라 CPU 성능이 데이터 수집 속도를 제한.
- 파싱(Parsing) 병목: 웹 페이지의 평균 크기가 2012년에 비해 몇 배나 커지면서, HTML을 분석하고 링크를 추출하는 파싱 과정이 예상외로 큰 비용을 차지. HTML 파서로 lxml을 사용하다가 selectolax로 전환하여 3배 이상의 성능 향상을 경험한 점은 실용적인 기술 인사이트를 줌.

이처럼 기술의 발전이 기존의 문제를 해결했지만, 동시에 새로운 차원의 문제를 낳았다는 점이 매우 흥미로운 인사이트였음

## 아키텍처에 대한 논의

이 프로젝트의 아키텍처는 교과서적인 분산 시스템 설계와는 거리가 있었음. 일반적인 시스템 디자인 인터뷰에서는 기능별(수집, 파싱, 저장소 등)로 서버 그룹을 나누라고 하지만, 이 프로젝트는 다른 방식으로 접근

- 선택한 아키텍처: 독립적인 고성능 노드 12개로 구성된 클러스터. 각 노드는 수집, 파싱, 데이터 저장(Redis) 등 모든 기능을 자체적으로 수행하는 완전체(All-in-one)입니다.
- 선택 이유: 저자는 예산과 시간 제약이 있기 때문에, 처음에는 단일 머신의 성능을 최대로 끌어올리는 것('수직적 확장')에 집중했음. 이 최적화된 단일 노드 구성을 그대로 복제하여 '수평적 확장'을 하는 것이 가장 빠르고 효율적인 방법이었다고 언급. 단순히 많은 데이터를 빠르게 수집하는 것이 아니라, 웹 생태계의 질서와 운영자들의 부담을 고려한 접근 방식이 인상적이었음. robots.txt 준수, 최소 70초 도메인 접근 간격, 요청 거절 시 수동 차단 등은 윤리적인 크롤링의 모범 사례로 보임.
- 장점: 노드 간 통신이 없어 설계가 단순하고, 특정 노드에 장애가 발생해도 다른 노드에 영향을 주지 않음.
- 단점: 저자도 언급했듯, 특정 노드에 할당된 도메인(예: wikipedia.org)이 너무 인기가 많으면 해당 노드만 과부하에 걸리는 '핫 샤드(Hot Shard)' 문제가 발생할 수 있음.

## 놀라웠던 의사결정

1. S3 대신 인스턴스 스토리지를 사용한 결정:
보통 대용량 데이터 저장은 당연히 AWS S3 같은 오브젝트 스토리지를 떠올릴 수 있음. 하지만 저자는 비용을 직접 계산해 보였고, 단기간 대량의 데이터를 저장하는 이 프로젝트의 경우 S3의 요청 비용과 저장 비용이 인스턴스 내장 스토리지보다 압도적으로 비싸다는 것을 증명. '교과서적인 정답'을 무조건 따르지 않고, 실제 제약 조건에 맞춰 비용을 꼼꼼히 분석하고 내린 결정이라는 점에서 매우 인상적.
2. JavaScript를 렌더링하지 않기로 한 결정:
저자는 JavaScript 렌더링 없이 순수 HTML만 분석했고, 그럼에도 불구하고 웹의 상당 부분이 여전히 크롤링 가능하다는 것을 보여주었습니다. 이는 문제의 범위를 현실적으로 좁혀 목표를 달성한 현명한 트레이드오프이자, 웹에 대한 우리의 통념에 질문을 던지는 결과였음.
3. 수평적 확장 전, 수직적 확장의 한계에 도전한 점:
처음부터 수평적 확장을 설계하기보다, 단일 머신의 성능을 극한까지 끌어올리려는 시도를 먼저 진행. 비록 이 시도는 소프트웨어적인 한계로 실패했지만, 그 과정을 통해 시스템의 병목을 명확히 이해할 수 있었음. 실패 과정을 솔직하게 공유하며 얻은 교훈을 설계에 반영한 점이 매우 현실적인 엔지니어링 접근법이라고 생각.
