# W2M5 - 올리브영 파운데이션 리뷰

---
## 목차
- [1. 비즈니스 아이디어 제안](#1-비즈니스-아이디어-제안)
- [2. 데이터셋](#2-데이터셋)
- [3. 방법론](#3-방법론)
- [4. 결과](#4-결과)
- [5. 추가 데이터 분석](#5-추가-데이터-분석)
- [6. 결론 및 논의](#6-결론-및-논의)

Team #1 : DE박건희, DE유혜원, DE오민우

---

## 1. 비즈니스 아이디어 제안

### 1) 제안 배경

- 올리브영은 국내 최대/유일의 헬스&뷰티 전문 스토어로, 다양한 종류의 메이크업 제품과 간식, 헬스 용품을 판매하고 있다.
- 올리브영의 웹 페이지는 다양한 리뷰를 제공하는 등 소비자친화적으로 구성되어 있으며, 제품의 기간별 랭킹과 세일 품목을 한 눈에 파악할 수 있도록 하여 합리적인 구매결정을 지원하고 있다.
- 특히, 피부 화장의 기초가 되는 베이스 메이크업 제품의 경우 분기별로 신제품을 출시될 만큼 활발한 시장을 형성하고 있다.
- 그러나, 베이스 메이크업 제품의 리뷰 평가 항목은 '발색력', '지속력', '발림성', '수분감' 네 가지로만 제시되어 있다.
- 실질적으로 소비자들이 베이스 메이크업 제품 구매시 가장 중요하게 생각하는 '색상'에 대한 고려가 빠져있는 것이다. 따라서 소비자들은 항상 많은 양의 리뷰를 일일이 읽으며 구매 여부를 결정할 수밖에 없다.
    <img width="1061" height="453" alt="oliveyoung_review_2" src="https://github.com/user-attachments/assets/ff1c6d99-4d85-4723-ab6c-3398764f8823" />
    
- 아래의 실제 리뷰처럼, 대부분의 리뷰에는 제품의 '색상'과 관련된 언급이 많지만, 이를 정량적/시각적으로 확인하기는 어려운 실정이다. 이에, 제품의 색상에 관련한 긍정적/부정적 리뷰를 워드클라우드를 통해 한 눈에 파악할 수 있는 프로토타입을 구상하였다.

    <img width="791" height="170" alt="oliveyoung_review_3" src="https://github.com/user-attachments/assets/12b95096-e80b-4a3f-ab71-d581ddd87503" />
    

### 2) 예상 소비자

- 파운데이션이란 피부의 톤을 보정하고 잡티를 커버하기 위해 쓰는 제품으로, 액체형, 크림형, 파우더형 등 다양한 제형으로 출시되고 있다.
- 색상은 핑크, 베이지, 옐로우 등으로 나뉘며, 밝기는 호수(숫자)로 표시되고 숫자가 클수록 어둡다.
- 시중에 올리브영에서 판매하는 파운데이션의 대표적 밝기는 대략 17호 ~ 25호로 나뉘며, 현재 대한민국에서 가장 많이 판매되고 있는 호수는 21호, 23호 등이 있다.
    - [https://v.daum.net/v/M0OcuRk1yD?f=p](https://v.daum.net/v/M0OcuRk1yD?f=p)
- 본 프로토타입의 예상 소비자는 **VDL사의 커버스테인 퍼펙팅 파운데이션 30ml** 제품을 어떤 색상 및 밝기로 구매해야 할지 고민 중인 잠재적 소비자와 회사의 마케팅 팀으로 구상하였다.
    
    [제품 링크]
    
    [https://www.oliveyoung.co.kr/store/goods/getGoodsDetail.do?goodsNo=A000000178635&dispCatNo=1000001000200010002&trackingCd=Cat1000001000200010002_Small&t_page=카테고리관&t_click=파운데이션_전체__상품상세&t_number=2](https://www.oliveyoung.co.kr/store/goods/getGoodsDetail.do?goodsNo=A000000178635&dispCatNo=1000001000200010002&trackingCd=Cat1000001000200010002_Small&t_page=%EC%B9%B4%ED%85%8C%EA%B3%A0%EB%A6%AC%EA%B4%80&t_click=%ED%8C%8C%EC%9A%B4%EB%8D%B0%EC%9D%B4%EC%85%98_%EC%A0%84%EC%B2%B4__%EC%83%81%ED%92%88%EC%83%81%EC%84%B8&t_number=2)
    

### 3) 예상 비즈니스 가치

- 소비자 구매 전환율 향상
    - 현재 소비자는 리뷰를 일일이 하나씩 읽어가며, 해당 제품이 본인이 원하는 특성에 부합하는지를 추정해야 한다.
    - 예를 들어 21호 피부의 소비자가 다크닝이 적고, 다른 제품보다 밝게 나온 파운데이션을 구매하고 싶은 상황에서, 12,000개가 넘는 올리브영의 리뷰를 읽어가며 제품의 특성을 파악하는 것은 매우 비효율적이며, 이러한 고민 과정에 지쳐 구매로 이어지지 않는 경우가 많다.
        - 다크닝이란, 화장 후 시간이 지나면서 피부톤이 어두워지는 현상을 의미한다.
    - Word cloud를 통해 색상 관련 긍/부정 리뷰를 한 눈에 확인할 수 있다면, 소비자의 고민 시간을 줄이고 구매 전환율을 높일 수 있다.
    - 또한, 회사에서 마케팅을 진행할 때 소비자들이 긍정적으로 남긴 키워드를 통해 진행하여 질좋은 마케팅을 진행할 수도 있다.
    

### 4) 서비스 확장 및 재사용성

- 본 프로토타입은 색상과 관련된 키워드에 집중하였지만, 자극도, 향기 등 다양한 제품 특성과 관련하여 워드클라우드를 제공하도록 확장할 수 있다.
- 나아가, 베이스 메이크업 제품이 아닌 헬스, 간식 등의 제품에도 확장하여 적용 가능하다.

### 5) 목표

- 우리는 이러한 예상 비즈니스 가치와 확장 가능성을 고려하여, 사용자가 남긴 리뷰가 긍정적인지 부정적인지를 판단하고, 핵심 키워드를 뽑아 사용자들이 한 눈에 해당 파운데이션의 장점과 단점을 인지할 수 있게 해준다.
- 추가로 회사의 마케팅 팀이나 개발 부서에서는 사용자들의 리뷰를 보고 마케팅의 방향성과 화장품의 품질 개선에도 도움을 줄 수 있을 것으로 기대한다.
- 또한 word cloud 분석에만 그치지 않고 실질적으로 근거에 기반이 될 수 있는 추가적인 분석을 통하여  예상 비즈니스 가치를 더 높일 수 있음을 기대한다.

## 2. 데이터셋

### 1) ETL 파이프라인

- log
    - 파이프라인의 모든 시작과 끝 부분에서 로그를 저장해준다.
    
    ```python
    def log_message(msg):
        """
        각 스텝마다 로그를 남김
        """
        now = datetime.now().strftime('%Y-%B-%d-%H-%M-%S')  # 정해진 로그 형식에 맞춤
        if not os.path.exists("./oliveyoung_etl_logs"):    # 폴더가 존재하지 않으면 생성
            os.makedirs("./oliveyoung_etl_logs")
        with open("./oliveyoung_etl_logs/etl_project_log.txt", "a") as f:
            f.write(f"{now}, {msg}\n")
    ```
    

- Extract
    
    ```python
    def crawl_paginated_reviews(url, option_text):
        """
        페이지에 접속해 리뷰 HTML을 수집 (Extract)
    
        각 단계는 아래와 같음:
        1) 페이지 접속 및 새로고침: 새로고침을 하지 않을 시에 봇으로 간주되어 추출이 불가능
        2) 사람임을 확인하는 체크박스 수동 클릭 (직접 클릭)
        3) 리뷰 탭 클릭
        4) 전체 상품 중 원하는 옵션 선택
        5) 리뷰 HTML을 페이지를 넘이면서 수집
        """
        log_message("Start Extract Step")
        options = Options()
        options.add_argument("start-maximized")
        options.add_argument("disable-infobars")
        options.add_argument("--disable-extensions")
        options.add_argument("--disable-blink-features=AutomationControlled")
        options.add_argument("user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36")
        options.add_experimental_option("excludeSwitches", ["enable-automation"])
        options.add_experimental_option('useAutomationExtension', False)
    
        driver = webdriver.Chrome(options=options)
    
        stealth(driver,
                languages=["ko-KR", "ko"],
                vendor="Google Inc.",
                platform="MacIntel",
                webgl_vendor="Intel Inc.",
                renderer="Intel Iris OpenGL Engine",
                fix_hairline=True,
        )
    
        driver.execute_cdp_cmd("Page.addScriptToEvaluateOnNewDocument", {
            "source": """
                Object.defineProperty(navigator, 'webdriver', {
                    get: () => undefined
                })
            """
        })
    
        all_html_pages = []
    
        try:
            driver.get(url)
            time.sleep(3)
            driver.refresh()
            time.sleep(3)
    
            WebDriverWait(driver, 15).until_not(
                EC.text_to_be_present_in_element((By.CSS_SELECTOR, "div.prd_recommend"), "고객님을 위한 상품추천중이에요")
            )
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight * 0.5);")
            time.sleep(3)
    
            review_tab = WebDriverWait(driver, 10).until(
                EC.element_to_be_clickable((By.CSS_SELECTOR, "#reviewInfo"))
            )
            driver.execute_script("arguments[0].scrollIntoView(true);", review_tab)
            review_tab.click()
            time.sleep(3)
    
            try:
                all_option_btn = WebDriverWait(driver, 10).until(
                    EC.element_to_be_clickable((By.CSS_SELECTOR, "a.sel_option.item.all"))  # 상품 옵션 선택
                )
                all_option_btn.click()
                time.sleep(3)
            except Exception as e:
                print("전체 상품옵션 버튼 클릭 실패:", e)
    
            try:
                option_element = WebDriverWait(driver, 10).until(
                    EC.presence_of_element_located((By.XPATH, f'//span[@class="txt" and contains(text(), "{option_text}")]'))
                )
                driver.execute_script("arguments[0].scrollIntoView(true);", option_element)
                option_element.click()
                time.sleep(3)
            except Exception as e:
                print("옵션 선택 실패:", e)
    
            WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "div.review_cont div.txt_inner"))  # 리뷰 텍스트가 있는지 확인
            )
    
            product_name = driver.find_element(By.CSS_SELECTOR, "div.review_cont p.item_option").text.strip()   # 상품 이름 추출
            page_num = 1
    
            while True:
                print(f"페이지 {page_num} 수집 중...")
                html = driver.page_source
                all_html_pages.append((html, product_name))
    
                try:
                    next_button = driver.find_element(By.CSS_SELECTOR, f'div.pageing a[data-page-no="{page_num + 1}"]')
                    driver.execute_script("arguments[0].scrollIntoView(true);", next_button)
                    next_button.click()
                    time.sleep(5)
                    page_num += 1
                except:
                    try:
                        next_block = driver.find_element(By.CSS_SELECTOR, 'div.pageing a.next')
                        driver.execute_script("arguments[0].scrollIntoView(true);", next_block)
                        next_block.click()
                        time.sleep(5)
                        page_num += 1
                    except:
                        print("마지막 페이지 도달")
                        break
    
        finally:
            driver.quit()
            log_message("End Extract Step")
        return all_html_pages
    ```
    
    - Extract 파이프라인은 아래와 같다:
    - 특정 제품 URL을 input으로 주어 페이지에 접속한다.
    - 접속이 안정적으로 됐을 시에 새로고침(Refresh)를 작동시켜준다. 새로고침을 해줘야 하는 이유는 아래와 같다:
        - 새로고침을 하지 않았을 시에, 봇으로 간주되어 리뷰가 보이지 않는다.
        - 새로고침을 하면 아래와 같은 화면이 나오는데,
        <img width="652" height="506" alt="image" src="https://github.com/user-attachments/assets/f65bbbcd-8bb9-4c4f-82f9-bfe8bbaeb5da" />

        
        - 이 부분에서는 사람이 직접 손으로 사람임을 인증해야한다. (마우스 클릭 한번)
        <img width="1152" height="645" alt="image 1" src="https://github.com/user-attachments/assets/564e4558-ae8f-4f02-9eea-745e59ecd347" />

    
    - 그 다음 리뷰 버튼을 누른 뒤에, 좌측에 보이는 전체 상품 옵션 radio box에서 우리가 원하는 제품이 자동으로 선택된다.
    - 제품이 선택되면, 페이지의 html을 가져오게 된다.
    - 모든 페이지의 html을 자동으로 쌓아 Transform으로 전달하게 된다.
    
- Transform
    
    ```python
    def extract_reviews_from_html(html, product_name):
        """
        추출한 HTML에서 데이터를 추출하여 데이터 프레임 형태로 변환 (Transform에 종속됨)
        """
        soup = BeautifulSoup(html, "lxml")
        review_list = soup.select("div.review_list_wrap ul.inner_list li") 
        data = []
    
        for li in review_list:
            txt_tag = li.select_one("div.review_cont div.txt_inner")    # 리뷰
            review_text_raw = txt_tag.get_text(strip=True) if txt_tag else None
            review_text = review_text_raw if review_text_raw else None
    
            skin_tag = li.select_one(".info .user .tag span")   # 피부 타입
            skin = skin_tag.get_text(strip=True) if skin_tag else None  # 모든 사용자가 피부 타입을 명시하지 않아, 있는 사람만 추출
    
            poll_items = li.select("div.review_cont div.poll_sample dl.poll_type1 dd span.txt") # 발색력, 지속력, 발림성, 수분감 추출
            발색력 = poll_items[0].get_text(strip=True) if len(poll_items) > 0 else None
            지속력 = poll_items[1].get_text(strip=True) if len(poll_items) > 1 else None
            발림성 = poll_items[2].get_text(strip=True) if len(poll_items) > 2 else None
            수분감 = poll_items[3].get_text(strip=True) if len(poll_items) > 3 else None
    
            score_tag = li.select_one("div.review_cont div.score_area span.review_point span.point")    # 별점
            star_value = None
            if score_tag:
                style_val = score_tag.get("style", "")
                if "width:" in style_val:
                    pct = float(style_val.split(":")[1].replace("%", "").strip())
                    star_value = round(pct / 20, 1)
    
            if review_text and star_value is not None:
                data.append({
                    "product_name": product_name,
                    "star": star_value,
                    "review": review_text,
                    "skin": skin,
                    "발색력": 발색력,
                    "지속력": 지속력,
                    "발림성": 발림성,
                    "수분감": 수분감
                })
        return data
    
    def transform_reviews(html_pages):
        """
        리뷰 데이터를 데이터 프레임으로 변환 (Transform)
        이 과정에서 리뷰 텍스트 정리
        """
        log_message("Start Transform Step")
        all_data = []
        for html, product_name in html_pages:
            extracted = extract_reviews_from_html(html, product_name)
            all_data.extend(extracted)
        df = pd.DataFrame(all_data)
        df['review'] = df['review'].apply(clean_text)
        log_message("End Transform Step")
        return df
    ```
    
    - 추출된 html에서 우리가 원하는 정보만 가져오도록 한다.
    - 여기서는 상품 이름, 별점, 리뷰, 리뷰어의 피부톤, 발색력, 지속력, 발림성, 수분감을 가져와서 분석하려 한다.
    
    ```python
    def clean_text(text):
        """
        텍스트에 이모지나 특수문자가 포함되어 있을 경우 이를 제거하고 정리된 텍스트 반환
        """
        text = re.sub(r'[^\w\sㄱ-ㅎ가-힣.,!?]', '', text)  # 이모지 및 특수문자 제거
        text = re.sub(r'\s+', ' ', text)  # 공백 정리
        return text.strip()
    ```
    
    - 추출된 리뷰는 이모지나 특수문자가 있는지 확인 후 있으면 필터링을 통해 삭제해준다.
    - 텍스트 정리까지 끝나면 데이터 프레임 형태로 저장해준다.
    
- Load
    
    ```python
    def load_reviews(df, filename):
        """
        데이터 프레임을 CSV 파일로 저장 (Load)
        """
        log_message("Start Load Step")
        df.to_csv(filename, index=False, encoding="utf-8")
        log_message("End Load Step")
    ```
    
    - 데이터 프레임을 CSV 파일로 저장해준다.
    
    ```python
    def safe_filename(text):
        # 파일 이름에 사용할 수 없는 문자 제거 또는 변환
        return re.sub(r'[\\/:"*?<>|]+', '_', text)  # 슬래시 포함 특수문자 → 언더스코어로 대체
    ```
    
    - 파일 이름에는 ‘/’ 와 같은 기호를 사용하지 못해서 이러한 기호를 _(언더바)로 바꿔준다.

### 2) 데이터셋 개요

- 이 과정을 통해 우리는 올리브영 파운데이션 제품 중 인기 제품군인 [기획] A02(+세레니티 쿠션 미니), [단품] A02(핑크/미디엄톤 21호), [기획] A02(21호/핑크베이지) 의 리뷰 총 2,200개를 수집하였다.
    - 각 제품들은 같은 제품이지만, 기획의 차이만 있다.
- 이 3개의 기획 제품의 리뷰 페이지는 별도로 구성되어 있기 때문에 각 기획별로 리뷰들을 별도로 가져와서 병합해 분석해야 한다.
- 각 기획 제품마다 최대 1,000개의 리뷰밖에 보지 못하기 때문에, 기획 제품 별 1,000개의 리뷰만 가져와 분석을 진행했다.
- 올리브영 리뷰 특성상, 4점 이하는 좋지 않은 내용의 댓글이라 판단되어, 별점 5점은 긍정(label = 1), 4점 이하는 부정(label = 0)로 labeling을 진행해줬다.
- 아래는 각 데이터셋에 대한 개요이다:
    - [기획] A02(+세레니티 쿠션 미니): 200개 (긍정 리뷰: 164, 부정 리뷰: 36)
    - [단품] A02(핑크/미디엄톤 21호): 1,000개 (긍정 리뷰: 794개, 부정 리뷰: 206개)
    - [기획] A02(21호/핑크베이지): 1,000개 (긍정 리뷰: 868개, 부정 리뷰: 132개)

## 3. 방법론

- 우리는 각 리뷰 하나 당 3개의 핵심 키워드를 추출하여 word cloud로 시각화한 뒤 추가 분석을 진행했다.

### 1) Word Cloud

- Word Cloud는 텍스트 데이터에서 자주 등장하는 단어를 시각적으로 표현한 그래픽이다. 단어의 빈도수가 높을수록 크고 두드러지게 표시되어, 핵심 키워드를 직관적으로 파악할 수 있게 해주어 텍스트 분석, 감정 분석, 리뷰 요약 등에 자주 활용된다.
- 시각적으로 정보 전달이 쉬워 발표 자료나 리포트에서 유용하게 사용되는 형식이다.
- Python에서는 WordCloud 라이브러리를 통해 간단히 생성할 수 있다.
- 아래는 word cloud의 예시이다:
  
    <img width="927" height="518" alt="image 2" src="https://github.com/user-attachments/assets/39943e97-1d08-4fa6-8b8f-389952684dce" />

    
    출처: [https://resilienteducator.com/classroom-resources/word-clouds-writing/](https://resilienteducator.com/classroom-resources/word-clouds-writing/)
    
- 기준에 따라 달라지지만, 일반적으로 중요한 단어는 크게 표시하여 사용자들이 한번에 중요한 요소를 판단하기에 매우 유용한 툴이다.

### 2) KcELECTRA 기반 핵심 키워드 추출

- 먼저 모든 리뷰를 가져와서 분석하기 보단 [기획] A02(21호/핑크베이지)만을 가져와 핵심 키워드를 뽑아 wordcloud 프로토타입 분석을 진행하기로 하였다.
    - 이 프로토타입을 통해 분석 방법론을 구체화하며, 초기 결과를 본 뒤에 방법론 수정 여부를 정하려 했다.
- 프로토타입은 [기획] A02(21호/핑크베이지)의 1,000개 리뷰를 가져와서 진행했다.

- 접근법
    - 앞에서 언급했듯이, 1,000개만 가져온 뒤에 프로토타입 분석 수행을 하고 초기 결과가 괜찮으면 데이터셋을 확장하여 분석한다.
    
    ```python
    import pandas as pd
    
    df = pd.read_csv('/21_reviews_score.csv')
    df['label'] = df['star'].apply(lambda x: 1 if x == 5.0 else 0)
    df = df[['review', 'label']].dropna()
    df.head()
    ```
    
    - [기획] A02(21호/핑크베이지) label의 분포는 긍정(별점 5점)이 868개, 부정(별점 4점 이하)이 132개였다.
    - 리뷰에서 핵심 키워드를 뽑는 방법은 Transformer 기반의 Language model인 BERT 기반의 모델로 선택하였다. 그러나 BERT는 한국어 처리에 취약해서, BERT를 기반으로 한국어 처리까지 되게 해주는 KcELECTRA를 선택했다.
        - Transformer는 자연어 처리에서 널리 사용되는 딥러닝 모델 구조로, 입력 문장에서 단어 간의 관계를 Attention 메커니즘을 통해 파악한다.
        - Attention 메커니즘은 문장에서 각 단어가 다른 단어에 얼마나 집중해야 하는지를 계산하는 방법이다. 예를 들어 “그녀는 사과를 먹었다”라는 문장에서 “먹었다”가 “사과”에 주목해야 하는데, Attention은 이런 의미적 연결을 수치로 표현해준다.
    - https://github.com/Beomi/KcELECTRA
    - KcELECRTA는 온라인 뉴스에서 댓글과 대댓글을 수집해 구어체와 신조어에도 강한 특성을 가진 Transformer 기반 언어 모델이다.
    - 우리는 이 모델을 통해서 하나의 리뷰 당 핵심 키워드라고 생각되는 단어를 명사화시켜 3개를 추출했다.
    
    ```python
    from transformers import AutoTokenizer, AutoModel
    import torch
    
    tokenizer = AutoTokenizer.from_pretrained("beomi/KcELECTRA-base-v2022")
    model = AutoModel.from_pretrained("beomi/KcELECTRA-base-v2022", output_attentions=True)
    model.eval()
    ```
    
    - Pretrained된 모델이기 때문에 평가용으로만 가져왔고, attention을 통하여 단어의 중요도를 확인해야하기 때문에 output_attentions은 True로 설정해줬다.
    
    ```python
    import re
    import emoji
    from soynlp.normalizer import repeat_normalize
    
    emojis = ''.join(emoji.EMOJI_DATA)
    pattern = re.compile(f'[^ .,?!/@$%~％·∼()\x00-\x7Fㄱ-ㅣ가-힣{emojis}]+')
    url_pattern = re.compile(
        r'https?:\/\/(www\.)?[-a-zA-Z0-9@:%._\+~#=]{1,256}\.[a-zA-Z0-9()]{1,6}\b([-a-zA-Z0-9()@:%_\+.~#?&//=]*)')
    
    import re
    import emoji
    from soynlp.normalizer import repeat_normalize
    
    pattern = re.compile(f'[^ .,?!/@$%~％·∼()\x00-\x7Fㄱ-ㅣ가-힣]+')
    url_pattern = re.compile(
        r'https?:\/\/(www\.)?[-a-zA-Z0-9@:%._\+~#=]{1,256}\.[a-zA-Z0-9()]{1,6}\b([-a-zA-Z0-9()@:%_\+.~#?&//=]*)')
    
    def clean(x): 
        x = pattern.sub(' ', x)
        x = emoji.replace_emoji(x, replace='') #emoji 삭제
        x = url_pattern.sub('', x)
        x = x.strip()
        x = repeat_normalize(x, num_repeats=2)
        return x
        
        
    import re
    from kiwipiepy import Kiwi
    kiwi = Kiwi(typos='basic_with_continual')
    kiwi.typo_cost_weight = 7          # 과도 교정 방지
    
    _HANGUL_ONLY = re.compile(r'^[가-힣]+$')
    _BAD_ENDING = re.compile(r'(요|니다|니댜|어요)$')
    _HAS_EN_NUM  = re.compile(r'[A-Za-z0-9]')
    
    ALLOWED = {'NNG', 'XSN'}           # 부분 형태소 허용 태그
    
    def is_strict_noun(word: str, min_len=2, max_len=10) -> bool:
        """후보 단어가 순수 명사(XSN 포함)인지 2단계로 검사"""
        if not (min_len <= len(word) <= max_len):
            return False
        if _HAS_EN_NUM.search(word) or not _HANGUL_ONLY.fullmatch(word):
            return False
        if _BAD_ENDING.search(word):
            return False
    
        # 다시 kiwi.tokenize -> 서브 태그 전부 허용 범위?
        for sub in kiwi.tokenize(word, split_complex=True):
            if sub.tag not in ALLOWED:
                return False
        return True
    
    def extract_final_nouns(text, *, min_len=2):
        res, buf, cnt, last_tag, last_end = [], "", 0, None, 0
        toks = kiwi.tokenize(text, split_complex=True, normalize_coda=False)
    
        for t in toks:
            form, tag = t.form, t.tag
            st, ed   = t.start, t.start + t.len
            gap      = text[last_end:st].isspace()
            last_end = ed
    
            # 공백·버퍼초과 시 flush
            if gap or cnt >= 2:
                if is_strict_noun(buf, min_len):
                    res.append(buf)
                buf, cnt, last_tag = "", 0, None
    
            # NNG
            if tag == 'NNG':
                if cnt == 0:
                    buf, cnt = form, 1
                elif cnt == 1 and last_tag == 'NNG':
                    buf += form; cnt = 2
                else:
                    if is_strict_noun(buf, min_len):
                        res.append(buf)
                    buf, cnt = form, 1
                last_tag = 'NNG'
    
            # XSN -> NNG 뒤 한 번만
            elif tag == 'XSN' and cnt == 1 and last_tag == 'NNG':
                buf += form; cnt = 2; last_tag = 'XSN'
    
            # 기타 품사 -> flush & reset
            else:
                if is_strict_noun(buf, min_len):
                    res.append(buf)
                buf, cnt, last_tag = "", 0, None
    
        if is_strict_noun(buf, min_len):
            res.append(buf)
        return res
    ```
    
    - 모델로만 단어를 추출하게 되면, “지속력”과 같은 복합명사가 추출되지 않기 때문에 이러한 부분까지 출력이 되고 과도한 오타는 정정해서 출력하게, 고유명사는 추출되지 않게 필터링 함수를 만들었다.
        - 고유명사를 추출할 수 있게 한다면, 오타를 고유명사로 인식하여 핵심 키워드로 오타가 뽑히는 경우가 잦다.
        - 아무리 오타를 정정해서 출력하게 해도 language model의 한계로 정정되지 않는 단어가 많다.
    
    ```python
    def extract_top_attention_words(text, tokenizer, model, noun_candidates, top_k=3):
        """
        주어진 명사 후보들 중 attention이 가장 높은 top_k 단어를 리스트로 반환
        """
        tokens = tokenizer(text, return_tensors='pt', truncation=True, max_length=64)
        input_ids = tokens['input_ids']
        
        with torch.no_grad():
            outputs = model(**tokens)
            attentions = outputs.attentions
    
        last_layer_attention = attentions[-1][0]  # (heads, seq, seq)
        mean_attention = last_layer_attention.mean(dim=0)  # (seq, seq)
        cls_attention = mean_attention[0]
    
        tokens_decoded = tokenizer.convert_ids_to_tokens(input_ids[0])
        attention_scores = []
    
        for token, score in zip(tokens_decoded, cls_attention):
            token_clean = token.replace("##", "")
            if token in ["[CLS]", "[SEP]"] or token.startswith("##"):
                continue
            if token_clean in noun_candidates:
                attention_scores.append((token_clean, score.item()))
    
        # 중요도 순 정렬 후 top_k만 반환
        if attention_scores:
            attention_scores.sort(key=lambda x: -x[1])
            top_words = [word for word, _ in attention_scores[:top_k]]
            return top_words
        else:
            return []
            
    from collections import defaultdict
    from tqdm import tqdm
    
    positive_words = defaultdict(float)
    negative_words = defaultdict(float)
    
    top_k = 3 # 추출할 키워드 개수
    
    for _, row in tqdm(df.iterrows(), total=len(df)):
        text = clean(row['review'])
        label = row['label']
    
        noun_candidates = extract_final_nouns(text)
        if not noun_candidates:
            continue
        
        keywords = extract_top_attention_words(text, tokenizer, model, noun_candidates, top_k=top_k)
        if not keywords:
            continue
    
        for kw in keywords:
            if label == 1:
                positive_words[kw] += 1
            else:
                negative_words[kw] += 1
    ```
    
    - 주어진 명사 후보들 중 attention이 가장 높은 top_k 단어를 리스트로 반환하는 함수를 만든 뒤에 attention score가 가장 높은 3개의 단어만 추출하게 설정하였다.
    - 이때, 긍정 리뷰와 부정 리뷰의 핵심 키워드는 따로 분석해야 하기 때문에 별개로 저장하였다.
    - 이때의 결과는 [결과 항목의 1번](#1-kcelectra-word-cloud-결과)에서 확인할 수 있듯이, 단어의 임베딩이 latent dimension에 잘 표현되지 않아, 단어간 중요도의 정확도가 떨어졌다고 판단했다.
        - 문제에 대한 설명은 결과 챕터에 자세히 작성했다.
    - 그래서 우리는 추가로, LLM 기반으로 핵심 키워드를 추출하는 방향으로 분석을 진행했다.
    

### 3) HyperClova X 기반 핵심 키워드 추출

- 네이버에서 개발한 한국어 특화 하이퍼클로바X는 한국어 기반에서는 기존 모델들에 비해 아주 훌륭한 성능을 보여준다.
  
    <img width="1280" height="549" alt="image 3" src="https://github.com/user-attachments/assets/ed854f4d-6e35-4756-813e-2e46dd19d753" />
    
- 위의 통계는 한국어 기반 질의에서 훌륭한 성능을 보여줌을 나타낸다.
- 이 통계를 기반으로 우리는 KcELECTRA보다 하이퍼클로바X가 핵심 키워드를 더 잘 뽑아줄 것을 기대하며 실험을 진행했다.
- 총 2,200개의 수집한 모든 리뷰를 가지고 실험을 진행하였다.

```python
import json
import requests
import time

def clova_keyword_extraction(review_text):
    url = "https://clovastudio.stream.ntruss.com/testapp/v3/chat-completions/HCX-005"
    headers = {
        'Authorization': 'Bearer nv-735b9c8de942461ca71a834c0b3c1b7aBLuo', 
        'Content-Type': 'application/json; charset=utf-8',
        'Accept': 'text/event-stream',
        'X-NCP-CLOVASTUDIO-REQUEST-ID': 'keyword_extraction_001'
    }
    messages = [
        {
            "role": "system",
            "content": (
                "당신은 한국어 리뷰로부터 주요 키워드를 추출하는 전문가입니다. "
                "리뷰에서 핵심 명사 3개를 한글 단어로 콤마(,)로 구분해서 출력하세요. "
                "복합 명사는 빼고 알파벳이 포함된 단어는 무조건 제외하세요."
                "오타처럼 보이는 단어는 무조건 제외하세요."
                "예시: 커버력, 지속력, 밀착력"
                "포함하면 안되는 예시: 브이디엘, 피부, 파운데이션, 파데, 화장, v02, a02, VDL 등 알파벳을 포함한 단어"
            )
        },
        {"role": "user", "content": f'리뷰: "{review_text}" 핵심 키워드를 뽑아줘'}
    ]

    payload = {
        "messages": messages,
        "topP": 0.8,
        "topK": 0,
        "maxTokens": 128,
        "temperature": 0.5,
        "repetitionPenalty": 1.1,
        "stop": [],
        "includeAiFilters": True,
        "seed": 0
    }
    
    try:
        result = None
        with requests.post(url, headers=headers, json=payload, stream=True, timeout=15) as r:
            for line in r.iter_lines(decode_unicode=True):
                if not line or not line.startswith("data:"):
                    continue
                content = line.removeprefix("data:").strip()
                if not content.startswith("{"):
                    continue
                obj = json.loads(content)
                if "message" in obj and "content" in obj["message"]:
                    result = obj["message"]["content"]
                if obj.get("finishReason") == "stop":
                    break

        if result:
            keywords_list = [k.strip() for k in result.split(",") if len(k.strip()) >= 2]
            return ", ".join(keywords_list)
        return None

    except Exception as e:
        print(f"[ERROR] {e}")
        return None
```

- 코드는 HyperClova X에게 **한국어 리뷰로부터 주요 키워드를 추출하는 전문가**라고 임명을 해준 뒤에, 핵심 명사를 추출하라고 프롬프트를 줬다.
    - 이 과정에서 영어로 된 제품명이나, 이전 실험의 경험을 통해 피부, 파운데이션, 파데, 화장, 쿠션과 같은 감정이 드러나지 않는 단어는 제거해서 확인했다.

```python
def clova_keyword_extraction_retry_safe(text, retries=3):
    for _ in range(retries):
        result = clova_keyword_extraction(text)
        if result:
            return result
        time.sleep(1.5) 
    return None
```

- 스트리밍 형식으로 값을 받아오는 것이다 보니 계속해서 요청을 하면 llm에서 request limit으로 인해 응답을 주지 않을 수가 있다. 이 문제를 해결하기 위하여 응답을 받는데 실패하면 retry를 3번까지 수행하도록 안전장치 함수를 구현했다.

```python
from tqdm import tqdm

results = []
batch_start_time = time.time()
counter = 0
max_calls = 60
interval_sec = 70

for idx, row in tqdm(df.iterrows(), total=len(df)):
    review_text = row['review']
    result = clova_keyword_extraction_retry_safe(review_text)
    results.append(result)
    counter += 1

    # 10개에 한 번 출력
    if (idx + 1) % 10 == 0:
        print(f"[{idx+1}개 완료] 예시: {result}")

    # 60개마다 속도 제어
    if counter >= max_calls:
        elapsed = time.time() - batch_start_time
        if elapsed < interval_sec:
            wait = interval_sec - elapsed
            print(f"{counter}개 처리 완료. {wait:.1f}초 대기 중")
            time.sleep(wait)
        batch_start_time = time.time()
        counter = 0

df['llm_keywords'] = results
```

- 추가 확인 결과, HyperClova X는 60초당 60개의 응답이 최대 응답량이라는 것을 확인하여, 60개의 응답을 하나의 사이클로 정의하고 한 사이클당 무조건 안전하게 70초를 채워야 다음 사이클로 넘어가게 구현했다.
- HyperClova X로 핵심 키워드를 뽑아 word cloud로 그린 결과는 [결과 챕터의 2번째 항목](#2-hyperclova-x-word-cloud-결과)에서 볼 수 있다.

### 4) 추가 유사도 계산

- 키워드 단어 임베딩 벡터를 생성하고, 이를 활용해 색상과 관련된 단어와의 유사도를 계산한 후 키워드를 필터링하여 word cloud를 다시 생성한다.
- 기존의 word cloud는 긍/부정 키워드 중 중복되는 키워드가 많아 워드클라우드의 직관적 해석이 어렵다는 한계가 있었다.
- 따라서, 긍/부정 키워드를 빈도수 및 유사도에 기반하여 재구성하고, 프로토타입의 목적에 맞게 색상 및 제품의 특성과 최대한 관련있는 word cloud를 생성하였다.

- 단어 임베딩
    - fastText 사전학습 모델(`cc.ko.300.bin`)을 사용하여 각 단어를 벡터 공간으로 변환한다.
    - fastText는 subword(음절/문자 n-gram) 기반으로 동작하기 때문에, 사전에 없는 단어(OOV)도 벡터를 계산할 수 있으며, None 값이 나오지 않는다.
        - [https://fasttext.cc/](https://fasttext.cc/)
        - n-gram은 문장에서 n개의 연속된 단어 묶음을 의미하는 개념이다. 문장, “나는 밥을 먹었다” 를 예시로 들면
            - 1-gram (unigram): 나는, 밥을, 먹었다
            - 2-gram (bigram): 나는 밥을, 밥을 먹었다
            - 3-gram (trigram): 나는 밥을 먹었다
    - `get_embedding(word)` 함수를 통해 하나의 단어 벡터를 얻고,
    - `embedding(keywords, color_words)` 함수를 통해 키워드와 색상 관련 단어들의 벡터를 각각 계산한다.
    
- 단어 임베딩 벡터 간 유사도 계산
    - 각 키워드 벡터와 색상 관련 단어 벡터들 간의 코사인 유사도를 계산한다.
    - `get_similarity()` 함수는 `sklearn.metrics.pairwise.cosine_similarity`를 사용해 유사도를 계산한 후,
      가장 유사한 색상 단어와 유사도 점수를 찾는다.
    - 유사도 결과에는 각 키워드별로 아래를 포함한다.
        - 가장 유사한 색상 단어(`closest_color_word`)
        - 해당 키워드의 빈도(`frequency`)
        - 유사도 점수(`similarity`)
        - 키워드의 레이블(`label`)
    - 최종 결과는 유사도 점수 기준으로 내림차순 정렬된 `pandas.DataFrame`으로 반환된다.
    
    ```python
    import pandas as pd
    from sklearn.metrics.pairwise import cosine_similarity
    import matplotlib.pyplot as plt
    from wordcloud import WordCloud
    import fasttext
    
    def get_embedding(word):
        """
        fastText를 사용하여 주어진 단어의 임베딩 벡터를 반환합니다.
    
        매개변수:
            word (str): 임베딩할 단어
    
        반환값:
            numpy.ndarray: 단어의 임베딩 벡터
        """
        return model.get_word_vector(word)
    
    def preprocessing(df):
        """
        입력 데이터프레임의 llm_keywords를 파싱하고 정리합니다.
    
        - 'llm_keywords' 컬럼을 문자열 리스트에서 실제 리스트로 변환
        - llm_keywords를 각 행마다 하나씩 분리
        - llm_keywords에서 선행 점(.) 제거
    
        매개변수:
            df (pandas.DataFrame): 'llm_keywords'와 'label' 컬럼을 포함한 데이터프레임
    
        반환값:
            pandas.DataFrame: 분리 및 정리된 llm_keywords와 label을 담은 데이터프레임
        """
        df = df.copy()
    
        df["llm_keywords"] = df["llm_keywords"].apply(lambda x: [kw.strip() for kw in x.split(",")])
        df = df.explode("llm_keywords")[["llm_keywords", "label"]]
        df["llm_keywords"] = df["llm_keywords"].str.replace(r'^\.+', '', regex=True)
    
        return df
    
    def add_label_and_frequency(df):
        """
        각 llm_keywords별로 가장 많이 등장한 label과 등장 빈도를 계산합니다.
    
        - 각 llm_keywords에 대해 가장 많이 등장한 label(최빈값)을 구합니다.
        - 각 llm_keywords의 등장 횟수를 계산합니다.
        - 이를 하나의 데이터프레임으로 병합합니다.
    
        매개변수:
            df (pandas.DataFrame): 'llm_keywords'와 'label' 컬럼을 가진 데이터프레임
    
        반환값:
            pandas.DataFrame: 다음 컬럼을 포함한 데이터프레임
                - 'keyword': 고유한 키워드
                - 'frequency': 등장 횟수
                - 'label': 가장 많이 등장한 label
        """
        df = df.copy()
    
        result_df = (
            df.groupby("llm_keywords")
            .agg(
                frequency=("label", "count"),  # 등장 횟수
                label=("label", lambda x: x.value_counts().idxmax())  # 최빈값
            )
            .reset_index()
            .rename(columns={"llm_keywords": "keyword"})
        )
    
        result_df = result_df.dropna()
        
        return result_df
    
    def embedding(keywords, color_words):
        """
        주어진 keywords와 color_words를 임베딩 벡터로 변환합니다.
    
        각 단어를 get_embedding()으로 벡터로 변환하여 리스트로 반환합니다.
    
        매개변수:
            keywords (list of str): 임베딩할 키워드 리스트
            color_words (list of str): 임베딩할 색상 관련 단어 리스트
    
        반환값:
            tuple:
                - keyword_vecs (list of numpy.ndarray): 키워드 벡터 리스트
                - color_vecs (list of numpy.ndarray): 색상 단어 벡터 리스트
        """
        keyword_vecs = []
        for word in keywords:
            vec = get_embedding(word)
            keyword_vecs.append(vec)
    
        color_vecs = []
        for word in color_words:
            vec = get_embedding(word)
            color_vecs.append(vec)
        
        return keyword_vecs, color_vecs
    
    def get_similarity(keywords, keyword_vecs, color_words, color_vecs, keyword_df):
        """
        각 키워드와 색상 단어 간의 유사도를 계산하고 결과를 정리합니다.
    
        - 각 키워드 벡터와 모든 색상 벡터 간의 코사인 유사도를 계산합니다.
        - 가장 유사한 색상 단어를 찾습니다.
        - 키워드의 빈도와 라벨을 조회합니다.
        - 키워드가 color_words에 포함된 경우 유사도와 색상 단어를 강제로 지정합니다.
    
        매개변수:
            keywords (list of str): 키워드 리스트
            keyword_vecs (list of numpy.ndarray): 키워드 벡터 리스트
            color_words (list of str): 색상 단어 리스트
            color_vecs (list of numpy.ndarray): 색상 단어 벡터 리스트
            keyword_df (pandas.DataFrame): 'keyword', 'frequency', 'label' 정보를 가진 데이터프레임
    
        반환값:
            pandas.DataFrame: 유사도 내림차순으로 정렬된 데이터프레임
                - 'keyword': 키워드
                - 'closest_color_word': 가장 유사한 색상 단어
                - 'frequency': 등장 횟수
                - 'similarity': 유사도
                - 'label': 최빈값 라벨
        """
        results = []
    
        for kw, kw_vec in zip(keywords, keyword_vecs):
            if kw_vec is None:
                continue
    
            sims = cosine_similarity([kw_vec], color_vecs)[0]
            max_sim = sims.max()
            max_color = color_words[sims.argmax()]
    
            # 만약 키워드가 color_words 안에 있다면 강제로 설정
            if kw in color_words:
                max_sim = 1.0
                max_color = kw
    
            row = keyword_df[keyword_df["keyword"] == kw]
            if not row.empty:
                freq = int(row["frequency"].iloc[0])
                label = int(row["label"].iloc[0])
            else:
                freq = 0
                label = None
    
            results.append((kw, max_color, freq, max_sim, label))
    
        df = pd.DataFrame(
            results,
            columns=["keyword", "closest_color_word", "frequency", "similarity", "label"]
        )
    
        df = df.sort_values(by="similarity", ascending=False)
    
        return df
    
    def make_wordcloud(n, sim_df, mode, font_path='/System/Library/Fonts/Supplemental/AppleGothic.ttf'):
        """
        상위 N개의 긍정 또는 부정 키워드로 워드클라우드를 생성하여 출력합니다.
    
        - 라벨에 따라 긍정/부정 키워드를 선택합니다.
        - 선택된 키워드의 빈도로 워드클라우드를 생성합니다.
    
        매개변수:
            n (int): 워드클라우드에 포함할 키워드 수
            sim_df (pandas.DataFrame): 'keyword', 'frequency', 'label' 컬럼이 있는 데이터프레임
            mode (str): 'positive' 또는 'negative'
    
        예외:
            ValueError: mode가 'positive' 또는 'negative'가 아닐 때
    
        반환값:
            None
        """
        if mode.lower() == "positive":
            top_keywords = sim_df[sim_df["label"] == 1].head(n)
        elif mode.lower() == "negative":
            top_keywords = sim_df[sim_df["label"] == 0].head(n)
        else:
            raise ValueError("mode must be 'positive' or 'negative'")
    
        word_freq = {row['keyword']: row['frequency'] for _, row in top_keywords.iterrows()}
    
        wc = WordCloud(
            font_path=font_path,
            background_color='white',
            width=800,
            height=400
        )
    
        wc.generate_from_frequencies(word_freq)
    
        plt.figure(figsize=(10, 5))
        plt.imshow(wc, interpolation='bilinear')
        plt.axis("off")
        plt.title(f"{mode} Top Keywords Similar to Colors")
        plt.show()
    
    if __name__ == "__main__":
    
        model = fasttext.load_model("ko/cc.ko.300.bin")
    
        # Define color-related words
        color_words = [
        "색상", "컬러", "빨강", "노랑", "상아", "붉은", "누런", "다크닝", "밝은", "어두운", "분홍", "핑크", "베이지", "옐로우", "톤",
        "핑베", "뉴트럴", "쿨톤", "웜톤", "홍조", "화사", "브라이트", "내추럴", "뽀용", 
        ]
    
        # Load data
        df = pd.read_csv("oliveyoung_21호_최종분석.csv")
    
        # preprocess data
        keyword_df = preprocessing(df)
        keyword_df = add_label_and_frequency(keyword_df)
    
        # Get keywords list
        keywords = keyword_df["keyword"].tolist()
    
        # Embed keywords and color words
        keyword_vecs, color_vecs = embedding(keywords, color_words)
    
        # Calculate similarity
        sim_df = get_similarity(keywords, keyword_vecs, color_words, color_vecs, keyword_df)
    
        # Generate wordclouds
        make_wordcloud(n=200,sim_df=sim_df, mode="positive")
        make_wordcloud(n=50, sim_df=sim_df, mode="negative")
    ```
    
    - color_words 리스트는 12000여개의 리뷰를 직접 확인하며, 리뷰에 자주 등장한 색상과 관련한 단어들과 도메인 지식을 바탕으로 구성하였다.
    - 아래는 문맥 기반의 KcElectra를 사용하여 키워드를 임베딩한 결과와, 단어 사전 기반의 fastText를 사용하여 키워드를 임베딩한 결과를 비교한 표이다.
    - 문맥 기반의 모델로 단어를 임베딩할 때보다, 사전 학습된 단어 사전 기반으로 임베딩할 때 성능이 향상되었음을 알 수 있다.
    
    - KcElectra
        
        
        | index | keyword | closest_color_word | frequency | similarity | label |
        | --- | --- | --- | --- | --- | --- |
        | 515 | 핑크 | 핑크 | 16 | 1.000000 | 1 |
        | 193 | 뽀용 | 뽀용 | 2 | 1.000000 | 1 |
        | 318 | 웜톤 | 웜톤 | 1 | 1.000000 | 1 |
        | 392 | 주말 | 톤 | 1 | 0.975030 | 1 |
        | 445 | 케어 | 톤 | 1 | 0.971684 | 1 |
        | 215 | 선물 | 톤 | 3 | 0.971135 | 1 |
        | 378 | 제품 | 톤 | 57 | 0.970322 | 1 |
        | 2 | 가방 | 상아 | 1 | 0.970219 | 1 |
        | 358 | 자외선 | 톤 | 1 | 0.967923 | 1 |
        | 308 | 외출 | 톤 | 3 | 0.967625 | 1 |
        - 키워드와 색상 단어가 완전히 동일하여 유사도가 1인 경우를 제외하면, 육안으로 볼 때 색상과의 유사도가 낮은 단어 쌍임에도 불구하고 유사도가 1에 가깝게 계산되었다.
        - KcElectra는 문맥 기반의 모델이기 때문에, 키워드와 같이 문맥이 없이 단어만 주어질 때 임베딩 성능이 떨어진다.
        
    - fastText
        
        
        | index | keyword | closest_color_word | frequency | similarity | label |
        | --- | --- | --- | --- | --- | --- |
        | 161 | 베이지 | 베이지 | 2 | 1.000000 | 1 |
        | 515 | 핑크 | 핑크 | 16 | 1.000000 | 1 |
        | 210 | 색상 | 색상 | 52 | 1.000000 | 1 |
        | 72 | 뉴트럴 | 뉴트럴 | 1 | 1.000000 | 1 |
        | 444 | 컬러 | 컬러 | 16 | 1.000000 | 1 |
        | 512 | 핏미 | 쿨톤 | 1 | 0.682334 | 0 |
        | 482 | 퍼펙팅 | 쿨톤 | 3 | 0.651877 | 1 |
        | 440 | 커버력 | 웜톤 | 3 | 0.645632 | 1 |
        | 416 | 쫀쫀 | 웜톤 | 2 | 0.639848 | 1 |
        | 507 | 픽서 | 쿨톤 | 1 | 0.625634 | 1 |
        - 키워드와 색상 단어가 완전히 동일하여 유사도가 1인 경우를 제외하면, 대부분 화장품과 관련된 단어의 유사도가 높게 나왔고, KcElectra보다 임베딩 성능이 좋음을 확인하였다.
        
- 최종 결과는 [결과 4) 항목](#4-빈도-수-및-유사도-기반-word-cloud-결과)에서 확인할 수 있다.

## 4. 결과

### 1) KcELECTRA word cloud 결과

- 아래 두개의 사진은 KcELECTRA를 통해 핵심 키워드를 뽑은 뒤 word cloud로 표현한 그림들이다:
<img width="790" height="429" alt="image 4" src="https://github.com/user-attachments/assets/e2825a2d-d327-4c8b-ab6f-15c6c90bc2e0" />

<img width="790" height="429" alt="image 5" src="https://github.com/user-attachments/assets/a5e07bb4-e335-4356-a534-1636b8010cf3" />

- 이 결과의 문제점은 크게 3개를 뽑을 수 있다
    - 실제 케이스 스터디를 해봤을 때, 피부나 매트, 쿠션과 같은 단어는 크게 중요해보이지 않는 단어이다.
    - 실제로 리뷰를 봤을 때, 크게 중요하다고 생각되지 않는 단어들이 핵심 키워드로 추출되어 해석에 어려움을 느꼈다.
        - 다크닝과 같은 색상 관련된 리뷰들이 있었고, 이런 부분을 참고해야 하지만, 색상 관련된 단어들은 많이 추출되지 않았다.
- 앞에서도 말했듯이, 단어의 임베딩이 latent dimension에 잘 표현되지 않아, 단어간 중요도의 정확도가 떨어졌다고 판단했다.
    - Latent dimension이란, 단어를 모델이 학습할 수 있게 차원에 임베딩(단어를 자연어가 아니라 벡터로 바꿔줌)을 해야하는데, 이때의 차원을 의미한다.
    - 아마 한국어이기 때문에 정확도가 떨어질 것이라고 예상한다. (학습 데이터의 부족)

### 2) HyperClova X word cloud 결과
<img width="790" height="429" alt="image 6" src="https://github.com/user-attachments/assets/fcbfb5e2-cf3e-4eb7-8c2e-c86a1d4a9a22" />

<img width="790" height="429" alt="image 7" src="https://github.com/user-attachments/assets/a968f6ba-73d3-48af-a09a-e80477750fc3" />


- 긍정적인 리뷰의 경우, 지속력, 커버력, 색상, 발림성 측면에서 긍정적인 평가를 하였다.
- 부정적인 리뷰의 경우, 지속력, 커버력, 다크닝, 트러블, 무너짐 측면에서 부정적인 평가를 하였다.
- 긍/부정 리뷰 모두 비슷한 키워드가 많이 언급되었는데, 이는 사용자의 피부 타입에 따라 다르게 체감될 수 있기 때문으로 추정된다.
- 즉, 같은 제품을 사용하더라도 지속력 측면에서 긍정적으로 평가한 사람과, 부정적으로 평가한 사람이 존재하기 때문에 위와 같은 결과가 출력된 것이다.
- 예를 들어, ‘무너짐이 없어요’ 라는 긍정적인 리뷰와, ‘무너짐이 심해요’라는 부정적인 리뷰에서 공통적으로 ‘무너짐’ 키워드가 추출되기 때문에 위와 같이 공통적인 키워드가 다수 출력된다.
- 위의 결과는 사용자 입장에서 제품의 장/단점을 직관적으로 해석하기 어렵기 때문에, **빈도 수와 유사도를 기반으로 중요도 지수를 구한 후 키워드별로 라벨링**한 뒤, 워드 클라우드를 재구성하였다.
- 이러한 목적을 바탕으로 ‘색상’과 같이 관심있는 특성에 관련 있는 단어 위주로 워드 클라우드를 구성하기 위해 색상 단어를 구성하고, 유사도를 계산하였다.

### 3) 유사도 계산 기반 word cloud 결과

- 먼저 색상 단어들과 키워드 간의 유사도를 계산하고, 이를 기반으로 정렬한 후 워드클라우드를 구성하였다.
- **유사도 기준**으로 정렬
<img width="790" height="427" alt="output1" src="https://github.com/user-attachments/assets/159379b1-af99-4c54-a17a-15df3097d87e" />

<img width="790" height="427" alt="output2" src="https://github.com/user-attachments/assets/9cc1bbaf-2f80-473c-ba67-ee0adc6bc81c" />

- 색상과의 유사도를 기반으로 워드클라우드를 구성한 결과, 프로토타입에 목적에 맞게 색상과 관련한 키워드 기반으로 워드클라우드가 생성되었다.
- 이는 직관적인 해석이 가능하다는 장점이 있다.
    - 예를 들어, 해당 제품은 화사하다는 장점이 있고, 웜톤과 쿨톤에게 모두 긍정적인 리뷰를 받은 제품이라고 해석 가능하다.
    - 한편, 해당 제품은 건조하며 보습력이 떨어진다는 단점이 존재한다고 해석 가능하다.
- 이때, 단순히 유사도만을 기반으로 워드클라우드를 생성하는 것은 키워드의 등장 빈도 수를 고려하지 않아 리뷰에서 적게 등장한 단어가 워드클라우드에서 대표성을 갖게 된다는 한계가 존재한다.
    - 예를 들어, 다수의 쿨톤 사용자와 소수의 웜톤 사용자가 해당 제품에 대해 긍정적인 리뷰를 남겼을 때, 웜톤 사용자는 소수임에도 불구하고 키워드 자체가 색상과의 유사도가 높기 때문에 두 키워드 모두 워드클라우드에서 크게 출력된다.
    - 따라서 웜톤 사용자에게 맞는 제품인지, 쿨톤 사용자에게 맞는 제품인지 직관적인 해석이 불가능하다.
    

### 4) 빈도 수 및 유사도 기반 word cloud 결과

- 유사도만을 기준으로 워드클라우드를 생성하는 것에는 한계가 존재했으므로, 키워드 등장 빈도 수와 유사도를 동시에 고려하여 워드클라우드를 생성하였다.
- 아래의 수식을 통해 유사도와 빈도 수를 하나의 점수(score)로 결합하였다.

$$
\text{score} = \alpha \cdot \text{표준화된 유사도} + (1-\alpha) \cdot \text{표준화된 빈도수}
$$

```python
# frequency, similarity 가중평균
from sklearn.preprocessing import MinMaxScaler

def compute_combined_score(sim_df, alpha=0.7): # 유사도 비중을 더 크게 설정
    """
    유사도와 빈도수를 모두 고려한 점수를 계산합니다.

    Args:
        sim_df (pd.DataFrame): 'similarity', 'frequency', 'keyword'가 있는 데이터프레임
        alpha (float): 유사도에 줄 가중치 (0~1)

    Returns:
        pd.DataFrame: 'score' 컬럼이 추가된 데이터프레임
    """
    df = sim_df.copy()

    # 유사도와 빈도수 정규화 (0~1)
    scaler = MinMaxScaler()
    df["similarity_norm"] = scaler.fit_transform(df[["similarity"]])
    df["frequency_norm"] = scaler.fit_transform(df[["frequency"]])

    # 가중합
    df["score"] = alpha * df["similarity_norm"] + (1 - alpha) * df["frequency_norm"]

    return df.sort_values(by="score", ascending=False)
    
    
 def make_wordcloud_from_score(n, sim_df, mode, font_path='/System/Library/Fonts/Supplemental/AppleGothic.ttf'):
    """
    상위 N개의 긍정 또는 부정 키워드를 점수(score) 기준으로 워드클라우드로 생성해 출력합니다.

    - 라벨에 따라 긍정/부정 키워드를 선택합니다.
    - 선택된 키워드의 점수(score)로 워드클라우드를 생성합니다.

    매개변수:
        n (int): 워드클라우드에 포함할 키워드 개수
        sim_df (pandas.DataFrame): 'keyword', 'score', 'label' 컬럼을 가진 데이터프레임
        mode (str): 'positive' 또는 'negative' 모드 지정

    예외:
        ValueError: mode가 'positive'나 'negative'가 아닐 경우

    반환값:
        None
    """
    if mode.lower() == "positive":
        top_keywords = sim_df[sim_df["label"] == 1].head(n)
    elif mode.lower() == "negative":
        top_keywords = sim_df[sim_df["label"] == 0].head(n)
    else:
        raise ValueError("mode must be 'positive' or 'negative'")

    word_freq = {row['keyword']: row['score'] for _, row in top_keywords.iterrows()}

    wc = WordCloud(
        font_path=font_path,
        background_color='white',
        width=800,
        height=400
    )

    wc.generate_from_frequencies(word_freq)

    plt.figure(figsize=(10, 5))
    plt.imshow(wc, interpolation='bilinear')
    plt.axis("off")
    plt.title(f"{mode} Top Keywords Similar to Colors")
    plt.show()

combined_df = compute_combined_score(sim_df, alpha=0.7)
make_wordcloud_from_score(n=200, sim_df=combined_df, mode = "positive")
make_wordcloud_from_score(n=200, sim_df=combined_df, mode = "negative")
```
<img width="790" height="427" alt="output5" src="https://github.com/user-attachments/assets/0994d0c7-fa40-48f1-8f67-b641a19c5fd4" />

<img width="790" height="427" alt="output6" src="https://github.com/user-attachments/assets/2197b015-eb2d-4b97-ba7c-4ee82ec72eb0" />

- 그 결과, 위와 같이 직관적인 해석이 가능한 워드클라우드가 출력되었다.
- 긍정 리뷰의 경우, 해당 제품은 다크닝 현상이 적으며, 화사한 편이고, 핑크 베이스이며, 쿨톤 사용자에게 잘 맞는 제품임을 알 수 있다.
- 한편, 부정 리뷰를 보면 건조하며, 피부 트러블이 날 수 있고, 유분감이 많다는 단점이 존재함을 알 수 있다.
- 또한, 부정적인 리뷰에서 색상에 대한 키워드가 많지 않은 것으로 미루어볼 때, 색상 측면에서는 해당 제품이 강점을 갖는다고 해석할 수 있다.
- 한편 부정 리뷰에서 ‘애정템’과 ‘퍼펙팅’의 경우, 색상 단어와의 유사도가 약 0.6으로 높은 편으로 계산되었기 때문에 실질적으로 색상과 관련이 없지만 크게 출력되었다.
- 이러한 결과의 원인을 ‘애정템’, ‘퍼펙팅’과 같은 외래어, 신조어의 경우 사전학습된 단어 사전에 포함되지 않아 단어 임베딩이 잘못 되었기 때문이라고 추측해 볼 수 있다. 이는 fastText 모델의 한계로도 해석 가능하다.

## 5. 추가 데이터 분석

- 추가로 우리는 word cloud로는 확인하기 힘든 부분을 분석하기 위하여 추가 데이터 분석을 수행하였다.
- 각 분석의 결과와 해석은 아래 항목에서 설명한다.

### 1) 소비자가 생각하는 제품의 중심 키워드
<img width="790" height="590" alt="image 8" src="https://github.com/user-attachments/assets/a5b5c7d6-c2e8-4a08-a129-51a8359206a8" />


- 소비자가 주로 사용하는 키워드 중에 비교적으로 자주 등장한 키워드를 중심으로 감정 점수를 산출하였다. 식은 아래와 같다:

$$
\frac{(review_{pos} - review_{neg})}{review_{total}}
$$

- 여기서 $review_{pos}$ 는 해당 키워드가 등장한 긍정적인 댓글 수, $review_{neg}$는 부정적인 댓글 수, $review_{total}$은 전체 댓글의 수를 의미한다.
- 감정 점수는 해당 키워드가 등장한 전체 리뷰 중에 긍정 혹은 부정적인 리뷰의 횟수를 비교하여 긍정적인 리뷰에서 해당 키워드가 많이 등장할수록 높은 점수를 갖는다.
- 소비자들이 작성한 리뷰에서 제품을 선호하게 된 가장 큰 요인이 된 키워드는 **붉은기, 쿨톤, 잡티**로 나타났다.
- 이는 ‘색상’과 관련한 특성이 제품의 선호도를 결정 짓는 중요한 요인이라고 해석 가능하다.
- 또한 이러한 결과는 긍정적인 댓글의 키워드로는 자주 뽑혔지만 부정적인 댓글에서의 키워드로는 자주 혹은 거의 뽑히지 않았음을 시사한다.
- 즉, 감정 점수가 높은 키워드를 중심으로 마케팅을 기획하였을 때 제품의 장점을 가장 효과적으로 전달할 수 있을 것으로 해석할 수 있다.

### 2) 긍정/부정 리뷰 별 핵심 키워드
<img width="1389" height="690" alt="image 9" src="https://github.com/user-attachments/assets/21f77007-b81f-47f3-8081-149eb1400078" />


- 위 그림은 긍정/부정 리뷰 별 핵심 키워드를 보여준다.
- 각각의 긍정리뷰와 부정 리뷰에서 나온 핵심 키워드의 차를 기반으로 수치를 구했다. 식은 아래와 같다:

$$
\frac{keyword_{positive}}{ review_{positive}} - \frac{keyword_{negative}}{ review_{negative}}
$$

- 식에서 $keyword_{positive}$, $keyword_{negative}$ 는 긍정/부정 리뷰에서 나온 키워드를 의미하고, $review_{positive}$, $review_{nagetive}$는 긍정/부정 리뷰의 총 개수를 의미한다.
- 값이 양수라면, 핵심 키워드가 부정적인 리뷰에서보다 긍정적인 리뷰에서 나오는 비율이 더 높다는 것을 의미하고 음수는 그 반대를 의미한다.
- 즉, 이 그림은 사용자가 부정적인 느낌보다 긍정적인 느낌을 더 많이, 혹은 그 반대인 경우를 보인다.

- 긍정적인 키워드를 먼저 보자면, 지속력과 밀착력, 커버력이 보인다.
    - 만족을 했던 사람은 파운데이션이 지속력과 밀착력, 커버력 덕분에 긍정적인 리뷰를 남겼다고 해석할 수 있다.
    - 이런 점들은 마케팅 부서에서 적극 홍보하여 이러한 특징의 파운데이션을 구매하고자 하는 사람들에게 더 쉽게 접근할 수 있다.
    
- 반대로 부정적인 키워드를 보자면 다크닝, 트러블, 여드름, 매트 순으로 보인다.
    - 해당 파운데이션은 다크닝이 발생할 수 있다는 것을 보여준다. 결과 4)에서는 긍정적인 다크닝이 덜 일어난다는 것이 주요하다고 나왔지만, 추가 분석의 결과, 어떤 사람에게서는 다크닝이 자주 발생한다는 것을 확인할 수 있다.
        - 즉, 다크닝은 사람마다 다르게 체감될 수 있는 영역인 것을 확인할 수 있다.
    - 트러블과 여드름은 [4) 피부 유형별 반응](#4-피부-유형별-반응)에서 볼 수 있듯이, 트러블성 혹은 민감성 피부를 가진 사용자가 작성한 리뷰에 포함될 가능성이 있다는 것을 연관해서 볼 수 있다.
    - 마지막 매트는 [3) 제품의 강점 태그](#3-제품의-강점-태그)에서 볼 수 있듯이 파운데이션이 매트하기 때문에 부정적으로 생각하는 사용자가 어느정도 있음을 보여준다.
        - 이 점은 제품을 홍보할 때 촉촉하기 보다는 매트한 느낌이 있다고 언급하여, 이런 일을 방지하도록 할 수 있음을 시사한다.
    - 이런 점들은 개발 부서에서 더 나은 화장품으로 업그레이드하기 위한 수치로 활용될 수 있다.

### 3) 제품의 강점 태그
<img width="480" height="290" alt="image 10" src="https://github.com/user-attachments/assets/caecafac-3984-4c01-abb1-d867b3afb5ea" />

- 올리브영 제품 리뷰를 작성할 때, 발색력, 지속력, 발림성, 수분감에 대해 평가를 해야 리뷰가 정상적으로 업로드가 된다. 이 평가는 3점 척도이며, 우리는 이 점수를 토대로 가장 낮게 평가한 것을 0점, 가장 높게 평가한 것을 2점으로 정의하여 각 리뷰에 따라 어떻게 4개의 항목을 평가했는지를 조사했다.
    - 추가로, 수분감의 경우 0점은 매트하다, 2점은 촉촉하다로 긍정, 부정과는 무관하다.
- 그림에서 계산한 식은 아래와 같다:

$$
\sum_{i=1}^{k} \frac{score_{feature}}{review_{emotion}}
$$

- $score_{feature}$은  각 항목 당 점수를 의미하고 $review_{emotion}$은 긍정/부정의 리뷰 수를 의미한다.

- 전체 결과를 봤을 때, 발색력, 지속력, 발림성은 평균과 $\pm 0.2$  정도로 차이나는 것을 확인할 수 있다.
    - 그러나 긍정적인 리뷰에서 더 높은 점수를 줬음을 확인할 수 있다.
    - 이것은 파운데이션에 만족하는 사람들은 발색력, 지속력, 발림성에는 만족하는 모습을 보여주고, 부정적인 사람들 역시 중간 이상의 점수를 준 것을 확인할 수 있다.
- 수분감 항목의 경우에선 긍정적인 리뷰를 단 사람은 보통의 정도로 평가를 주로 했고, 부정적인 리뷰를 단 사람은 매트하다의 평가 비율이 높은것을 확인할 수 있다.
    - 이것은 파운데이션 자체가 수분감이 높진 않고, 매트함에 조금 더 가깝다고 볼 수 있다.
    - 이러한 매트함이 부정적인 리뷰로 이끌어갈 수 있다고 생각된다.

- 제품을 개선하려고자 한다면 매트함을 원하지 않는다면 다른 제품을 구매하게 유도하거나 매트하다고 마케팅을 하면 도움이 될 수 있음을 시사한다.

### 4) 피부 유형별 반응
<img width="1189" height="790" alt="image 11" src="https://github.com/user-attachments/assets/8d7d8bdb-84db-4392-9aa2-ee6d5c807c44" />

<img width="630" height="470" alt="image 12" src="https://github.com/user-attachments/assets/04c85d07-eeee-47f5-ad17-05353782981b" />

<img width="789" height="396" alt="image 13" src="https://github.com/user-attachments/assets/8aa5b370-1a43-4e28-b2ee-a0c7bc186a2a" />


- 자신의 피부 유형을 기재한 사람들의 리뷰 데이터를 기반으로 피부 별 반응을 산출하였다.
    - 복합성, 지성, 건성 순으로 많은 사람들이 이 파운데이션을 사용해보고 리뷰를 남긴 것을 확인할 수 있다.
- 약건성, 건성 피부를 가진 소비자의 제품 선호 비율이 높게 나왔고, 민감하거나 트러블이 자주 일어나는 피부를 가진 소비자들의 제품 선호 비율이 가장 낮게 관측되었다.
    - 하지만 이러한 경우, 피부가 민감하기 때문에 다른 파운데이션에도 같은 현상이 발생하는지 확인하여 추가적인 검증이 필요할 것으로 보인다.
- 가장 효과를 많이 볼 수 있는 소비자는 건성 피부를 가진 소비자일 것으로 생각되며, 이 데이터를 바탕으로 건성 피부의 소비자를 타겟으로 잡고 마케팅을 진행하면 유의미한 효과를 얻을 수 있을 것이라 예측된다.
- 추가로, 민감성이나 트러블성의 피부를 가진 사람을 위해 추가적인 제품군을 개발한 뒤에 구매를 유도하면 매출 상승에도 도움이 될 수 있음을 기대한다.

### 5) 각 상품 기획 별 소비자 반응
<img width="630" height="470" alt="image 14" src="https://github.com/user-attachments/assets/96215e72-74f7-4191-8ab6-b98fa3407397" />

<img width="630" height="470" alt="image 15" src="https://github.com/user-attachments/assets/5a0370bc-dcbe-4aa0-a8c2-344b9939b7a7" />


- 세 가지 제품군의 리뷰 데이터를 바탕으로 각 제품군의 선호도를 조사하였다
- 주로 ‘21호 / 핑크베이지’ 기획 상품을 구매한 소비자들로부터 가장 호평을 받았고, ‘[단품] A02 (핑크 미디엄톤 21호)’를 구매한 소비자들의 반응이 가장 좋지 못했다.
    - Word cloud에서도 볼 수 있듯, 가격이 비싸더라도 기획을 통해 추가 상품이 있는 제품을 이용자들이 선호한다는 것을 볼 수 있다.
    - 이는 추가적인 기획을 통해 이용자들의 구매를 유도할 수 있다는 인사이트를 제공한다.

## 6. 결론 및 논의

- 본 팀 활동에서는 올리브영의 파운데이션 리뷰 데이터를 기반으로, 소비자들이 구매 시 가장 중요하게 고려하는 요소 중 하나인 ‘색상’과 관련된 인사이트를 효과적으로 전달하기 위한 데이터 분석 및 시각화 프로토타입을 제안하였다.
- 기존의 리뷰 평가 항목에서는 ‘발색력’, ‘지속력’, ‘발림성’, ‘수분감’ 등만 제공되어, 소비자들은 색상과 관련된 정보를 얻기 위해 수많은 리뷰를 직접 읽어야 하는 불편함이 있었다. 이에, 리뷰 데이터를 수집하고, NLP 모델과 LLM을 활용하여 전처리한 후, fastText 임베딩과 코사인 유사도를 활용해 색상과 유사한 키워드를 추출한 뒤, 이를 워드클라우드로 시각화하는 과정을 구현하였다. 나아가, EDA를 통해 소비자의 특성과 리뷰 및 키워드의 긍/부정 분포에 대해 분석하고, 이를 통한 추후 활용 가능성에 대해서도 제안하였다.
- 본 프로토타입을 통해 소비자들은 색상과 관련된 긍정적/부정적 리뷰를 한눈에 확인할 수 있게 되어, 구매 결정에 필요한 시간을 줄이고 더 만족스러운 제품을 선택할 수 있게 된다. 또한, 브랜드와 제조사 입장에서도 소비자들이 선호하거나 불만을 가지는 색상 관련 요소를 파악해 제품 개선과 마케팅 전략 수립에 활용할 수 있다.
- 결과적으로 제안된 데이터 프로덕트는 소비자의 구매 전환율을 높이고, 플랫폼의 경쟁력을 강화하며, 데이터 기반의 B2B 서비스 확장 가능성까지 갖춘, 높은 비즈니스 가치를 지닌 솔루션임을 확인할 수 있었다.
- 본 분석 구조는 립스틱, 쿠션, 컨실러 등 색상 선택이 중요한 다른 카테고리에도 동일하게 적용 가능하며, 제품 속성에 따라 모델을 커스터마이징할 수 있는 확장성을 지닌다.
- 또한, 우리는 추가 분석을 통하여 핵심 키워드 뿐 아니라 다른 요소들이 구매 의사에 중요하게 작용할 수 있음을 보여줬다.
- 이러한 확장성은 긍정적인 키워드로 홍보할 수 있는 마케팅 부서 뿐 아니라 부정적인 키워드를 보고 제품을 개선시킬 수 있는 개발 부서에도 새로운 시각을 확장시킬 수 있어 중요하다.
- 다만, 리뷰 내 색상 표현이 주관적이고 다양하게 서술되는 한계로 인해 일부 키워드 추출의 정밀도가 떨어질 수 있으며, 향후에는 색상 명칭 표준화 및 사용자 프로필 기반 분석 등을 통해 정밀도를 더욱 개선할 수 있을 것이다.

  ## 7. W2M6 팀 활동

- Docker를 사용하는 이유가 뭘까요?
    - Docker를 사용하면 OS나 라이브러리를 통일서켜줄 수 있고, 다른 컴퓨터에서 같은 DB를 공유도 할 수 있을 것 같다.
    - 버전 관리에도 용이할 것 같다.
    - 새로운 OS를 매번 설치할 필요가 없다.
    - 컨텐이너를 컴퓨터들의 환경과 격리시킴으로써 로컬 환경에 대한 종속에서 벗어날 수 있다.
    - 가상 머신보다 경량화되고 쾌적하게 실행을 할 수 있다.
    - 배포에 용이하다.
    - Docker 생태계가 이미 잘 갖추어져 있기 때문에 어떻게 사용하는 지만 알면 사용하는데 큰 불편함이 없다.
    - 실행 환경을 통일하게 진행할 수 있다.

- 어떤 점은 더 불편한가요?
    - 깃허브와 다름
    - Jupyter 이미지를 가져와야 하는데, docker hub에서 어떤 이미지가 공식 이미지인지 알기가 어려워 힘들다.
    - 처음하는 사람들은 사용하는데 어려움을 느낄 수 있다.

- 이번 미션에서는 하나의 EC2에 하나의 Docker container를 배포했습니다. 만약에 여러대의 EC2에 여러 개의 컨테이너를 배포해야 한다면 어떻게 해야 할까요?
    - 그냥 하면 될 것 같다.
    - EC2의 보안 그룹이 다르면 문제가 생길 수도 있을 것이다.
    - 자동 복구, 로드밸런싱, 스케일링, 롤링 업데이트 등 강력한 기능 제공하는 쿠버네티스를 사용한다.
