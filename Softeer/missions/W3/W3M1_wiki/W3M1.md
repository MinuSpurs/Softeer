# W3M1

## Dockerfile

```docker
FROM ubuntu:20.04

RUN apt-get update && apt-get install -y \
    openjdk-8-jdk-headless \
    wget \
    ssh \
    rsync && \
    mkdir /var/run/sshd && \
    echo 'root:root' | chpasswd && \
    sed -i 's/#PermitRootLogin prohibit-password/PermitRootLogin yes/' /etc/ssh/sshd_config && \
    sed -i 's/#PasswordAuthentication yes/PasswordAuthentication yes/' /etc/ssh/sshd_config

ENV HADOOP_VERSION=3.3.6

RUN wget https://downloads.apache.org/hadoop/common/hadoop-${HADOOP_VERSION}/hadoop-${HADOOP_VERSION}.tar.gz && \
    tar -xzf hadoop-${HADOOP_VERSION}.tar.gz -C /usr/local/ && \
    mv /usr/local/hadoop-${HADOOP_VERSION} /usr/local/hadoop && \
    rm hadoop-${HADOOP_VERSION}.tar.gz

ENV HADOOP_HOME=/usr/local/hadoop
ENV PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
ENV JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64

RUN ssh-keygen -t rsa -P '' -f /root/.ssh/id_rsa && \
    cat /root/.ssh/id_rsa.pub >> /root/.ssh/authorized_keys && \
    chmod 0600 /root/.ssh/authorized_keys

COPY config/core-site.xml $HADOOP_HOME/etc/hadoop/
COPY config/hdfs-site.xml $HADOOP_HOME/etc/hadoop/
COPY config/mapred-site.xml $HADOOP_HOME/etc/hadoop/
COPY config/yarn-site.xml $HADOOP_HOME/etc/hadoop/

RUN mkdir -p /usr/local/hadoop/hdfs/namenode && \
    mkdir -p /usr/local/hadoop/hdfs/datanode

CMD service ssh start && /bin/bash
```

- FROM ubuntu:20.04: Docker 이미지의 기반이 될 OS로 Ubuntu 20.04 버전 사용
- Run apt-get update …: 패키지 목록을 업데이트하고 필요한 소프트웨어 설치
    - openjdk-8-jdk-headless: Hadoop은 Java로 만들어졌기 때문에 OpenJDK8을 설치
    - ssh, rsync: Hadoop 클러스터의 노드들은 SSH를 통해 서로 통신하고 데이터를 동기화
    - mkdir /var/run/sshd: SSH 데몬을 실행하는데 필요한 디렉토리 생성
    
- ENV HADOOP_VERSION=3.3.6: 사용할 Hadoop 버전을 환경 변수로 지정
- Apache 공식 사이트에서 압축 파일을 받은뒤 지정한 경로에 풀어주고 압축 파일을 삭제

- ENV HADOOP_HOME: Hadoop이 설치된 기본 경로를 환경 변수로 설정
- ENV PATH: 시스템 PATH에 Hadoop 실행파일과 스크립트 경로를 추가 (터미널 어디서든 hadoop 명령어를 사용하기 위함)
- ENV JAVA_HOME: Hadoop이 사용할 Java의 위치를 명시적으로 알려줌

- ssh-keygen … : RSA 방식의 SSH 키페어 생성
- COPY: Dockerfile에 있는 로컬 경로 config/ 디렉토리 안에 미리 준비해 둔 Hadoop 설정 파일들을 이미지 안의 Hadoop 설정 디렉토리로 복사
    - core-site.xml: Hadoop의 가장 기본적인 설정(파일 시스템 주소)
    - hdfs-site.xml: HDFS 관련 상세 설정(데이터 복제 수, NameNode/DataNode)
    - marped-site.xml: MapReduce 실행 환경을 YARN으로 지정하는 등의 설정을 담음
    - yarn-site.xml: YARN 리소스 매니저 설정

- CMD: 이 이미지로 컨테이너를 실행할 때 수행될 명령어 설정
    - service ssh start: 컨테이너가 시작될 때 SSH 서비스를 먼저 실행
    - /bin/bash: 그 후 bash를 실행하여 사용자가 컨테이너에 접속하여 직접 명령어를 입력할 수 있는 상태로 만듦

```bash
docker buildx build --platform linux/amd64 -t gapbu123/w3m1 --push .
```

- 로컬에서 Docker hub에 빌드를 한 뒤 push 해줌

```bash
docker pull gapbu123/w3m1
docker run -it --name W3M1 -P --hostname localhost gapbu123/w3m1
```

- EC2에서 docker hub에 올린 이미지를 pull한 뒤 run을 통해 컨테이너를 생성

```bash
hdfs namenode -format
```

- 이 명령어는 HDFS의 메타데이터 저장소(Namenode Storage Directory)를 초기화하는 작업인데, 초기 설치 후 1번만 실행해주면 됨
    - 2025-07-22 07:07:17,833 INFO common.Storage: Storage directory /usr/local/hadoop/hdfs/namenode has been successfully formatted.
    - 위와 같은 메시지가 나오면 성공

```bash
chown -R root:root /usr/local/hadoop/hdfs
```

- 디렉토리 소유자를 지정해줌

```bash
export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
export HADOOP_HOME=/usr/local/hadoop
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
```

- JAVA_HOME, HADOOP_HOME, PATH 설정해줌

```bash
echo "export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64" >> $HADOOP_HOME/etc/hadoop/hadoop-env.sh
```

- hadoop-env.sh에 JAVA_HOME 추가

```bash
export HDFS_NAMENODE_USER=root
export HDFS_DATANODE_USER=root
export HDFS_SECONDARYNAMENODE_USER=root
```

- HDFS_*_USER 환경 변수를 root로 지정해줌

```bash
start-dfs.sh
```

![image.png](W3M1%2023872994258d80fbb3f8c0e8ddfeaa03/image.png)

- 이렇게 출력되면 성공
    - http://<your-ec2-public-dns>:9870로 들어가서 정상 작동되는지 확인
    
    ![image.png](W3M1%2023872994258d80fbb3f8c0e8ddfeaa03/image%201.png)
    
    - 정상적으로 나옴을 확인했음

- HDFS에 디렉토리 생성 후 파일 만든 뒤 확인

```bash
hdfs dfs -mkdir /mydir
echo "Hello HDFS" > hello.txt
hdfs dfs -put hello.txt /mydir/
hdfs dfs -get /mydir/hello.txt hello_downloaded.txt
```

- 이 명령어를 통해 mkdir을 만든 뒤, hello.txt를 만든 뒤에 폴더에 넣어줌

![image.png](W3M1%2023872994258d80fbb3f8c0e8ddfeaa03/image%202.png)

- 정상적으로 저장된 것을 확인할 수 있음

![image.png](W3M1%2023872994258d80fbb3f8c0e8ddfeaa03/image%203.png)

- 인터페이스에서도 잘 보이는 것을 확인할 수 있음